{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204e374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import glob\n",
    "import os \n",
    "import umap\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "675dd3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_SAMPLE_SIZE = 100\n",
    "SLICE_SIZE = 10\n",
    "SAMPLE_SIZE_PER_SLICE = TOTAL_SAMPLE_SIZE / SLICE_SIZE\n",
    "LATENT_VECTOR_SIZE = 128\n",
    "UMAP_NEIGHBOURS = 50\n",
    "UMAP_MIN_DISTATNCE = 0.1\n",
    "UMAP_DIMENSIONS = 2\n",
    "OUTPUT_PATH = \"./output/\"\n",
    "FRONT_END_CSV_FILENAME = \"frontend_2d_embeddings_slices\"\n",
    "FRONT_END_CSV_HEADER = \"id, slice_id, x, y\"\n",
    "FRONT_END_CSV_COLUMNS = 4\n",
    "BACK_END_CSV_FILENAME = \"backend_latent_vectors_slices\"\n",
    "BACK_END_CSV_HEADER = \"id,{}\".format(','.join([str(x) for x in range(LATENT_VECTOR_SIZE)]))\n",
    "BACK_END_CSV_COLUMNS = LATENT_VECTOR_SIZE + 1 \n",
    "CSV_COMMENTS = \"\" # should the csv header have any text before the labels? (like '#' for python comment)\n",
    "CSV_FMT = \"%f\" #fmt \"%f\" ensures floats are not saved in the sci annotation format to to the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38adf4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(TOTAL_SAMPLE_SIZE % SLICE_SIZE == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d2a4bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sample = np.random.normal(0, 1, (TOTAL_SAMPLE_SIZE, LATENT_VECTOR_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ce0ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #273: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "reducer = umap.UMAP(n_neighbors=UMAP_NEIGHBOURS, min_dist=UMAP_MIN_DISTATNCE, n_components=UMAP_DIMENSIONS)\n",
    "embeddings = reducer.fit_transform(total_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "944d4e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running umap\n"
     ]
    }
   ],
   "source": [
    "# get a sample of random numbers\n",
    "total_sample = np.random.normal(0, 1, (TOTAL_SAMPLE_SIZE, LATENT_VECTOR_SIZE))\n",
    "print(\"Running umap\")\t\n",
    "# reduce the dimensions of the sample to UMAP_DIMENSIONS dimensions\n",
    "reducer = umap.UMAP(n_neighbors=UMAP_NEIGHBOURS, min_dist=UMAP_MIN_DISTATNCE, n_components=UMAP_DIMENSIONS)\n",
    "embeddings = reducer.fit_transform(total_sample)\n",
    "\n",
    "# get a pool of indexes to randomly choose from for each slice\n",
    "indexes_pool = np.arange(embeddings.shape[0])\n",
    "\n",
    "# get empty arr to store the slices AKA the slice\n",
    "# to be used on the frontend of the latent garden app\n",
    "embeddings_slices = np.zeros((SLICE_SIZE, SLICE_SIZE, FRONT_END_CSV_COLUMNS)) # x, y, slice id, vector id\n",
    "\n",
    "# slices of latent vectors\n",
    "# to be used on the backend\n",
    "latent_vectors_slices = np.zeros((SLICE_SIZE, SLICE_SIZE, BACK_END_CSV_COLUMNS)) # id, LATENT_VECTOR_SIZE vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48dac8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for slice_index in range(int(TOTAL_SAMPLE_SIZE/SLICE_SIZE)):\n",
    "    # get random indexes from the pool \n",
    "    indexes_selection = np.random.choice(indexes_pool, size=SLICE_SIZE, replace=False)\n",
    "    # What is position of the randomly chosen indexes in the indexes pool?\n",
    "    selected_indexes_positions = np.flatnonzero(np.isin(indexes_pool, indexes_selection))\n",
    "    # what is the id of each individual embedding and latent vector?\n",
    "    ids = np.arange(slice_index*SLICE_SIZE, slice_index*SLICE_SIZE+SLICE_SIZE)\n",
    "    # append the individual ids to the slice\n",
    "    embeddings_slices[slice_index, :, 0] = ids\n",
    "    # append slice index column to the slice, to which slice does the slice belong to?\n",
    "    embeddings_slices[slice_index, :, 1] = slice_index\t\t\t\t\n",
    "    # get embeddings at the randomly chosen indexes\n",
    "    embeddings_slices[slice_index, :, 2:FRONT_END_CSV_COLUMNS] = embeddings[indexes_selection]\n",
    "    # set the slice to the slices array\n",
    "    # get latent vectors\n",
    "    latent_vectors_slices[slice_index, :, 0] = ids\n",
    "    latent_vectors_slices[slice_index, :, 1:BACK_END_CSV_COLUMNS] = total_sample[indexes_selection]\n",
    "    # delete used indexes from the pool so they're not used in next slices\n",
    "    indexes_pool = np.delete(indexes_pool, selected_indexes_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4c2a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten slices to a single column\n",
    "embeddings_slices = np.reshape(embeddings_slices, (TOTAL_SAMPLE_SIZE, FRONT_END_CSV_COLUMNS))\n",
    "latent_vectors_slices = np.reshape(latent_vectors_slices, (TOTAL_SAMPLE_SIZE, BACK_END_CSV_COLUMNS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21ffa08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
