{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa3a41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 10 23:15:26 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:07:00.0  On |                  N/A |\r\n",
      "|  0%   48C    P8    16W / 170W |    367MiB / 12288MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1177      G   /usr/lib/xorg/Xorg                 35MiB |\r\n",
      "|    0   N/A  N/A      1703      G   /usr/lib/xorg/Xorg                119MiB |\r\n",
      "|    0   N/A  N/A      1831      G   /usr/bin/gnome-shell               76MiB |\r\n",
      "|    0   N/A  N/A      2949      G   /usr/lib/firefox/firefox          124MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f48b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump gpu memory\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20095355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ms/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ms/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "INFO:pytorch_pretrained_biggan.model:loading model ../pretrained/biggan-deep-512 from cache at ../pretrained/biggan-deep-512/pytorch_model.bin\n",
      "INFO:pytorch_pretrained_biggan.model:Model config {\n",
      "  \"attention_layer_position\": 8,\n",
      "  \"channel_width\": 128,\n",
      "  \"class_embed_dim\": 128,\n",
      "  \"eps\": 0.0001,\n",
      "  \"layers\": [\n",
      "    [\n",
      "      false,\n",
      "      16,\n",
      "      16\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      16,\n",
      "      16\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      16,\n",
      "      16\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      16,\n",
      "      8\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      8,\n",
      "      8\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      8,\n",
      "      8\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      8,\n",
      "      8\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      8,\n",
      "      4\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      4,\n",
      "      4\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      4,\n",
      "      2\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      2,\n",
      "      2\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      2,\n",
      "      1\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      1,\n",
      "      1\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      1,\n",
      "      1\n",
      "    ]\n",
      "  ],\n",
      "  \"n_stats\": 51,\n",
      "  \"num_classes\": 1000,\n",
      "  \"output_dim\": 512,\n",
      "  \"z_dim\": 128\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BigGAN(\n",
       "  (embeddings): Linear(in_features=1000, out_features=128, bias=False)\n",
       "  (generator): Generator(\n",
       "    (gen_z): Linear(in_features=256, out_features=32768, bias=True)\n",
       "    (layers): ModuleList(\n",
       "      (0): GenBlock(\n",
       "        (bn_0): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=2048, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=2048, bias=False)\n",
       "        )\n",
       "        (conv_0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_1): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=512, bias=False)\n",
       "        )\n",
       "        (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_2): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=512, bias=False)\n",
       "        )\n",
       "        (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_3): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=512, bias=False)\n",
       "        )\n",
       "        (conv_3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): GenBlock(\n",
       "        (bn_0): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=2048, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=2048, bias=False)\n",
       "        )\n",
       "        (conv_0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_1): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=512, bias=False)\n",
       "        )\n",
       "        (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_2): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=512, bias=False)\n",
       "        )\n",
       "        (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_3): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=512, bias=False)\n",
       "        )\n",
       "        (conv_3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): GenBlock(\n",
       "        (bn_0): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=2048, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=2048, bias=False)\n",
       "        )\n",
       "        (conv_0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_1): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=512, bias=False)\n",
       "        )\n",
       "        (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_2): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=512, bias=False)\n",
       "        )\n",
       "        (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_3): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=512, bias=False)\n",
       "        )\n",
       "        (conv_3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (3): GenBlock(\n",
       "        (bn_0): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=2048, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=2048, bias=False)\n",
       "        )\n",
       "        (conv_0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_1): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=512, bias=False)\n",
       "        )\n",
       "        (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_2): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=512, bias=False)\n",
       "        )\n",
       "        (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_3): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=512, bias=False)\n",
       "        )\n",
       "        (conv_3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (4): GenBlock(\n",
       "        (bn_0): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=1024, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=1024, bias=False)\n",
       "        )\n",
       "        (conv_0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_1): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (conv_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_2): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_3): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (conv_3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (5): GenBlock(\n",
       "        (bn_0): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=1024, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=1024, bias=False)\n",
       "        )\n",
       "        (conv_0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_1): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (conv_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_2): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_3): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (conv_3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (6): GenBlock(\n",
       "        (bn_0): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=1024, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=1024, bias=False)\n",
       "        )\n",
       "        (conv_0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_1): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (conv_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_2): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_3): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (conv_3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (7): GenBlock(\n",
       "        (bn_0): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=1024, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=1024, bias=False)\n",
       "        )\n",
       "        (conv_0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_1): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (conv_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_2): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_3): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (conv_3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (8): SelfAttn(\n",
       "        (snconv1x1_theta): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (snconv1x1_phi): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (snconv1x1_g): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (snconv1x1_o_conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (9): GenBlock(\n",
       "        (bn_0): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=512, bias=False)\n",
       "        )\n",
       "        (conv_0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_1): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=128, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=128, bias=False)\n",
       "        )\n",
       "        (conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_2): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=128, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=128, bias=False)\n",
       "        )\n",
       "        (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_3): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=128, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=128, bias=False)\n",
       "        )\n",
       "        (conv_3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (10): GenBlock(\n",
       "        (bn_0): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=512, bias=False)\n",
       "        )\n",
       "        (conv_0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_1): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=128, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=128, bias=False)\n",
       "        )\n",
       "        (conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_2): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=128, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=128, bias=False)\n",
       "        )\n",
       "        (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_3): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=128, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=128, bias=False)\n",
       "        )\n",
       "        (conv_3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (11): GenBlock(\n",
       "        (bn_0): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (conv_0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_1): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=64, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=64, bias=False)\n",
       "        )\n",
       "        (conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_2): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=64, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=64, bias=False)\n",
       "        )\n",
       "        (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_3): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=64, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=64, bias=False)\n",
       "        )\n",
       "        (conv_3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (12): GenBlock(\n",
       "        (bn_0): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "        (conv_0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_1): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=64, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=64, bias=False)\n",
       "        )\n",
       "        (conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_2): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=64, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=64, bias=False)\n",
       "        )\n",
       "        (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_3): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=64, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=64, bias=False)\n",
       "        )\n",
       "        (conv_3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (13): GenBlock(\n",
       "        (bn_0): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=128, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=128, bias=False)\n",
       "        )\n",
       "        (conv_0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_1): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=32, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=32, bias=False)\n",
       "        )\n",
       "        (conv_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_2): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=32, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=32, bias=False)\n",
       "        )\n",
       "        (conv_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_3): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=32, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=32, bias=False)\n",
       "        )\n",
       "        (conv_3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (14): GenBlock(\n",
       "        (bn_0): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=128, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=128, bias=False)\n",
       "        )\n",
       "        (conv_0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_1): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=32, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=32, bias=False)\n",
       "        )\n",
       "        (conv_1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_2): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=32, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=32, bias=False)\n",
       "        )\n",
       "        (conv_2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_3): BigGANBatchNorm(\n",
       "          (scale): Linear(in_features=256, out_features=32, bias=False)\n",
       "          (offset): Linear(in_features=256, out_features=32, bias=False)\n",
       "        )\n",
       "        (conv_3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (bn): BigGANBatchNorm()\n",
       "    (relu): ReLU()\n",
       "    (conv_to_rgb): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (tanh): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_dim = 128\n",
    "n_classes = 1000\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os \n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "# download stuff for one hot encoding of y categories\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# load big gan model\n",
    "\n",
    "import torch\n",
    "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample, display_in_terminal)\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "model = BigGAN.from_pretrained('../pretrained/biggan-deep-512')#model.to('cuda')\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9e2c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic image generation\n",
    "\n",
    "# Prepare a input\n",
    "# truncation = 0.4\n",
    "# class_vector = one_hot_from_names(['Blenheim spaniel'], batch_size=5)\n",
    "# noise_vector = truncated_noise_sample(truncation=truncation, batch_size=5, seed=50)\n",
    "\n",
    "# # All in tensors\n",
    "# noise_vector = torch.from_numpy(noise_vector)\n",
    "# class_vector = torch.from_numpy(class_vector)\n",
    "\n",
    "# # If you have a GPU, put everything on cuda\n",
    "# noise_vector = noise_vector.to('cuda')\n",
    "# class_vector = class_vector.to('cuda')\n",
    "# noise_vector.shape\n",
    "\n",
    "# # Generate an image\n",
    "# with torch.no_grad():\n",
    "#     output = model(noise_vector, class_vector, truncation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a54d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize z sample\n",
    "\n",
    "dim_z = 128\n",
    "y = np.linspace(0, dim_z, dim_z)\n",
    "truncation = 1.\n",
    "z = truncated_noise_sample(truncation=truncation, batch_size=1, seed=50)\n",
    "plt.scatter(y,z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d37a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a GPU put back on CPU\n",
    "#output = output.to('cpu')\n",
    "\n",
    "# If you have a sixtel compatible terminal you can display the images in the terminal\n",
    "# (see https://github.com/saitoha/libsixel for details)\n",
    "#display_in_terminal(output)\n",
    "\n",
    "# Save results as png images\n",
    "#save_as_images(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a112837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolation funcs\n",
    "\n",
    "def interpolate_linear(v1, v2, num_steps):\n",
    "  vectors = []\n",
    "  for x in np.linspace(0.0, 1.0, num_steps):\n",
    "    vectors.append(v2*x+v1*(1-x))  \n",
    "  return np.array(vectors)\n",
    "\n",
    "\n",
    "def interpolate_hypersphere(v1, v2, num_steps):\n",
    "\n",
    "  v1_norm = np.linalg.norm(v1)\n",
    "  v2_norm = np.linalg.norm(v2)\n",
    "  v2_normalized = v2 * (v1_norm / v2_norm)\n",
    "\n",
    "  vectors = []\n",
    "  for step in range(num_steps):\n",
    "    interpolated = v1 + (v2_normalized - v1) * step / (num_steps - 1)\n",
    "    interpolated_norm =  np.linalg.norm(interpolated)\n",
    "    interpolated_normalized = interpolated * (v1_norm / interpolated_norm)\n",
    "    vectors.append(interpolated_normalized)\n",
    "  return np.array(vectors)\n",
    "\n",
    "# im funcs\n",
    "\n",
    "def convert_to_images(obj):\n",
    "    \"\"\" Convert an output tensor from BigGAN in a list of images.\n",
    "        Params:\n",
    "            obj: tensor or numpy array of shape (batch_size, channels, height, width)\n",
    "        Output:\n",
    "            list of Pillow Images of size (height, width)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from PIL import Image\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Please install Pillow to use images: pip install Pillow\")\n",
    "\n",
    "    if not isinstance(obj, np.ndarray):\n",
    "        obj = obj.cpu().detach().numpy()\n",
    "\n",
    "    obj = obj.transpose((0, 2, 3, 1))\n",
    "    obj = np.clip(((obj + 1) / 2.0) * 256, 0, 255)\n",
    "\n",
    "    img = []\n",
    "    for i, out in enumerate(obj):\n",
    "        out_array = np.asarray(np.uint8(out), dtype=np.uint8)\n",
    "        img.append(Image.fromarray(out_array))\n",
    "    return img\n",
    "\n",
    "\n",
    "def save_as_images(obj, file_name='output'):\n",
    "    \"\"\" Convert and save an output tensor from BigGAN in a list of saved images.\n",
    "        Params:\n",
    "            obj: tensor or numpy array of shape (batch_size, channels, height, width)\n",
    "            file_name: path and beggingin of filename to save.\n",
    "                Images will be saved as `file_name_{image_number}.png`\n",
    "    \"\"\"\n",
    "    img = convert_to_images(obj)\n",
    "\n",
    "    for i, out in enumerate(img):\n",
    "        current_file_name = file_name + '_%d.png' % i\n",
    "        logger.info(\"Saving image to {}\".format(current_file_name))\n",
    "        out.save(current_file_name, 'png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a731437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare interpolation data \n",
    "num_interps = 20 \n",
    "truncation = 0.3\n",
    "\n",
    "y_v1 = one_hot_from_names(['rhinoceros beetle'], batch_size=1)\n",
    "y_v2 = one_hot_from_names(['roundabout'], batch_size=1)\n",
    "\n",
    "z_v1 = truncated_noise_sample(truncation=truncation, batch_size=1, seed=3213)\n",
    "z_v2 = truncated_noise_sample(truncation=truncation, batch_size=1, seed=1)\n",
    "\n",
    "#create interpolation for both the category and the z vector \n",
    "interps_z = interpolate_hypersphere(z_v1 , z_v2 , num_interps)\n",
    "interps_y = interpolate_hypersphere(y_v1,  y_v2, num_interps)\n",
    "\n",
    "interps_z = interps_z.reshape(num_interps, z_dim)\n",
    "interps_y = interps_y.reshape(num_interps, n_classes)\n",
    "\n",
    "interps_z = torch.from_numpy(interps_z)\n",
    "interps_y = torch.from_numpy(interps_y)\n",
    "\n",
    "interps_z = interps_z.to('cuda')\n",
    "interps_y = interps_y.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d6a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generated interpolated images\n",
    "with torch.no_grad():\n",
    "    output = model(interps_z, interps_y, truncation)\n",
    "    save_as_images(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc4516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preserve background\n",
    "\n",
    "#In this expermient we try to change the background of an arbitrary image \n",
    "#while keeping the foreground the same. We want the foregournd image to stay stable \n",
    "#so we need a function that preserves the values near zero but at the same time change the values away from zero.\n",
    "\n",
    "# vals near 0 = background features?\n",
    "# vals away from 0 = foreground features?\n",
    "\n",
    "truncation = 0.7\n",
    "\n",
    "y = one_hot_from_names(['tiger beetle'], batch_size=2)\n",
    "\n",
    "z = np.zeros((2,128))\n",
    "z_tmp = truncated_noise_sample(truncation=truncation, batch_size=1, seed=123)\n",
    "z[0] = z_tmp[0]\n",
    "# use sin func to modify values, values close to 0 stay close to 0, values away from 0 will be changed\n",
    "z[1] = np.sin(z_tmp[0])\n",
    "z = z.astype(np.float32)\n",
    "\n",
    "y = torch.from_numpy(y)\n",
    "z = torch.from_numpy(z)\n",
    "\n",
    "y = y.to('cuda')\n",
    "z = z.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "   output = model(z, y, truncation)\n",
    "   save_as_images(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zooming\n",
    "\n",
    "# We try to zoom into a certain category to see the details of the generated images. \n",
    "# In order to that we need increase the weights of the vectors. \n",
    "# This doesn't work unless each feature in the vector space has either the value 1 or -1. \n",
    "# This is done by dividing each value in the vector by its absolute value namely $z/|z|$. \n",
    "# Then we can provide scaling by multipling by increasing negative values. \n",
    "# Note that this is highly dependent on the seed we are choosing. \n",
    "# Here we choose the seed = 2. \n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "truncation = .7\n",
    "\n",
    "z_start = truncated_noise_sample(truncation=truncation, batch_size=1, seed=5432)\n",
    "\n",
    "zoom_steps = 5\n",
    "step_size = 0.2\n",
    "\n",
    "y = one_hot_from_names(['tiger beetle'], batch_size=zoom_steps)\n",
    "\n",
    "steps = np.arange(step_size,(zoom_steps*step_size)+step_size,step_size)\n",
    "print(steps)\n",
    "z = [-step*(z_start/np.abs(z_start)) for step in steps]\n",
    "z = np.array(z).reshape(zoom_steps, z_dim)\n",
    "\n",
    "y = torch.from_numpy(y)\n",
    "z = torch.from_numpy(z)\n",
    "\n",
    "y = y.to('cuda')\n",
    "z = z.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aebcbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "   output = model(z, y, truncation)\n",
    "   save_as_images(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "179916d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# breeding\n",
    "\n",
    "# The idea is simple we just average the incoded labels and use the same seed vector. We use the combination \n",
    "# y^=ay1+(1âˆ’a)y2\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "truncation = 1.\n",
    "a = 0.2\n",
    "\n",
    "z = truncated_noise_sample(truncation=truncation, batch_size=1, seed=1)\n",
    "y1 = one_hot_from_names(['albatross'], batch_size=1)\n",
    "y2 = one_hot_from_names(['pelican'], batch_size=1)\n",
    "y3 = a*y1+(1-a)*y2\n",
    "\n",
    "z = np.array([z,z,z]).reshape(3, 128)\n",
    "y = np.array([y1,y2,y3]).reshape(3, 1000)\n",
    "\n",
    "y = torch.from_numpy(y)\n",
    "z = torch.from_numpy(z)\n",
    "\n",
    "y = y.to('cuda')\n",
    "z = z.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07ccdffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saving image to output_0.png\n",
      "INFO:__main__:Saving image to output_1.png\n",
      "INFO:__main__:Saving image to output_2.png\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "   output = model(z, y, truncation)\n",
    "   save_as_images(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9d2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
